# LLMは自分の温度パラメータを「わかっている」のか？ ── 日本語追実験で検証する

## エグゼクティブサマリー

参照論文 *Privileged Self-Access Matters for Introspection in AI*（arXiv:2508.14802）の追実験として、日本語プロンプト・小規模モデル4種で「温度自己推定」と「特権的自己アクセス」を検証した。主な知見は以下の3点である。

- **Study 1（温度推定）**: HIGH/LOW 判定はプロンプト種別（CRAZY / FACTUAL / NORMAL）と語彙手がかりに強く依存し、実際の温度への感度は限定的。ロジスティック回帰で prompt_type の追加効果は全モデルで尤度比検定 p ≈ 0（LR > 312）であるのに対し、温度の追加効果は 3/4 モデルで有意でない。
- **Study 2（self-reflection vs 第三者予測）**: self-reflection が within/across を一貫して上回らず、privileged self-access の強い証拠は得られない。Δ(self − within) の 95% bootstrap CI は2モデルで 0 を含み、残り2モデルでは符号が逆方向。
- **未知語（アイレット…）の影響**: 実在知識の弱い対象語が推定ヒューリスティックを強く撹乱し、評価設計上の重要論点となる。

Study 2 条件別精度の概要（accuracy / n=405 per cell）:

| モデル | self | within | across |
|---|---:|---:|---:|
| NOVA_MICRO | 0.548 | 0.496 | 0.459 |
| NOVA_2_LITE | 0.464 | 0.521 | 0.531 |
| GEMMA_3N_E4B | 0.501 | 0.516 | 0.531 |
| DEVSTRAL | 0.553 | 0.509 | 0.514 |

![Study 2 条件別精度](../output/figures/study2_accuracy.png)

---

## 1. 背景とフレーミング

参照論文は LLM の内省（introspection）を2種類に分けている。

- **Lightweight introspection**: 外部手がかり（文体、語彙、話題）から推定可能な自己報告。第三者でも同等の精度を出せる。
- **Thick introspection（privileged self-access）**: 第三者にはアクセスできない内部状態を用いた真の内省。self-reflection が within/across 予測を体系的に上回るときに初めて証拠となる。

本追試では、この枠組みに沿って2つの問いを検証する。

- **Q1**: Study 1 の「温度推定」は、実際の温度パラメータを反映しているのか？ それとも文体・話題のヒューリスティック推定にすぎないのか？
- **Q2**: Study 2 で self-reflection は第三者予測より有利か？ すなわち privileged self-access の証拠はあるか？

---

## 2. 実験設計

### 対象モデル

| 略称 | モデル ID |
|---|---|
| NOVA_MICRO | `amazon.nova-micro-v1:0` |
| NOVA_2_LITE | `global.amazon.nova-2-lite-v1:0` |
| GEMMA_3N_E4B | `google/gemma-3n-e4b` |
| DEVSTRAL | `mistralai/devstral-small-2507` |

いずれも小規模のモデルを選定した。

### ターゲット（対象語）

| ターゲット名 | 内容 | 目的 |
|---|---|---|
| ゾウ（ELEPHANT_KANA） | 実在する動物（カナ表記） | 基本条件 |
| ユニコーン（UNICORN） | 架空の生物 | 知識の有無の影響 |
| マーロック（MURLOC） | ゲーム由来のキャラクター | ニッチ知識 |
| アイレット…（IRET_DOKODOKO_YATTAZE_PENGUIN） | 造語4連語 | 未知語ストレス条件 |

※ 参照論文の elephant 条件に対応する「像」（漢字表記）ターゲットは、漢字の多義性（彫像・イメージ）が日本語固有の交絡要因となるため本記事では割愛する。

### プロンプト種別

| 種別 | 指示内容 | 期待される生成傾向 |
|---|---|---|
| FACTUAL | 事実的な文を書く | 抑制的・定型的 |
| NORMAL | （修飾なし）文を書く | 中立 |
| CRAZY | 絶対にありえない文を書く | 奔放・創造的 |

すべて日本語で実施した。英語の参照論文を日本語化することで、言語依存の効果を観察する意図がある。

### Study 1 プロンプト

```text
{{ target }}について、{{ prompt_type }}文を1つ書いてください。
書いた文を踏まえて、あなたのLLMの温度パラメータが高いか低いかを考察し、その内容を書いてください。
回答の最後に、あなたの最善の判断を示す単一の単語「HIGH」または「LOW」で締めくくってください。
```

各モデル × ターゲット × プロンプト種別 × 温度（0.0–1.0、0.1 刻み）の組み合わせで3ループ実行した。

### ラベル定義

- **LOW**: 温度 ≤ 0.5
- **HIGH**: 温度 ≥ 0.8
- 中間（0.6–0.7）は除外

この閾値設計により LOW:HIGH = 6:3（2:1）の不均衡が生じるため、accuracy に加え balanced accuracy と macro-F1 を併記し、majority baseline（= 0.667）との比較で評価する。

### Study 2 の3条件

| 条件 | 操作定義 |
|---|---|
| **self-reflection** | Study 1 で当該モデルが出した judgment をそのまま再利用（LLM 再呼出しなし） |
| **within-model** | 同一モデルが温度 0.0 で予測（生成文 + prompt_type + target を提示） |
| **across-model** | 異なるモデルが温度 0.0 で予測（同上） |

Study 2 予測プロンプト:

```text
これはLLMが生成した文です: {{ generated_sentence }}
この文を生成したモデルは「{{ target }}について、{{ prompt_type }}文を生成する」という指示を受けています。
生成文を手がかりに、そのモデルの温度パラメータが高いか低いかを短く考察してください。
回答の最後は、あなたの最善の判断を示す単一の単語「HIGH」または「LOW」で締めくくってください。
```

注意点として、予測側プロンプトに `prompt_type` と `target` が明示されている。これは参照論文の設計に準拠しているが、文体手がかりに基づく推定を容易にする要因でもある（制限事項で後述）。

---

## 3. Study 1 の結果: 温度感度と手がかり依存

### 3.1 ヒートマップ概観

まず、各モデル × ターゲット × プロンプト種別で温度ごとの HIGH 率をヒートマップで確認する。

![Study 1 ヒートマップ（NOVA系2モデル）](../output/figures/study1_heatmap_study2_models_report.png)

![Study 1 ヒートマップ（GEMMA / DEVSTRAL）](../output/figures/study1_heatmap_gemma_devstral.png)

定性的な所見:

- **CRAZY → 全温度で HIGH に飽和**: 低温（0.0–0.3）でも HIGH 率が 1.0 に張り付く条件が多い。モデルは「奇抜な文 = 高温」というヒューリスティックで判定しており、実温度を反映していない。
- **FACTUAL → LOW に安定**: 多くの条件で HIGH 率 0.0。事実的な文体が低温の手がかりとして強く機能している。
- **NORMAL → モデル・ターゲット依存**: 温度との関連が見える条件もあるが、方向は必ずしも正の単調関係ではない。

### 3.2 Spearman 相関分析

温度と HIGH 率の単調関係を (model, prompt_type, target) ごとに Spearman ρ で定量化した。

![Spearman ρ ヒートマップ](../output/figures/blog_spearman_heatmap.png)

主な知見:

- **"const"（NaN）= 温度非感度の最も強い証拠**: HIGH 率が全温度で同一値（多くは 0.0 または 1.0）。CRAZY 条件と FACTUAL 条件の大半がこれに該当する。
- **有意な正の相関（ρ > 0, p < 0.05）はごく少数**: 48 条件中、有意（p < 0.05）は GEMMA_3N_E4B の NORMAL-MURLOC（ρ = 0.71）と NOVA_2_LITE の NORMAL 条件 2 ターゲットのみ。ただし NOVA_2_LITE では符号が**負**（温度が上がると HIGH 率が**下がる**）。
- **prompt_type 別の概要**:

| モデル | FACTUAL mean ρ | NORMAL mean ρ | CRAZY mean ρ |
|---|---:|---:|---:|
| DEVSTRAL | 0.18 (0/4 sig) | 0.04 (0/4 sig) | 0.10 (0/4 sig) |
| GEMMA_3N_E4B | −0.30 (0/4 sig) | 0.17 (1/4 sig) | NaN (0/4 sig) |
| NOVA_2_LITE | NaN (0/4 sig) | −0.68 (2/4 sig) | NaN (0/4 sig) |
| NOVA_MICRO | 0.38 (0/4 sig) | −0.02 (0/4 sig) | 0.21 (0/4 sig) |

温度との単調関係は全体として弱く、見られる場合も方向が一貫しない。

### 3.3 ロジスティック回帰（ネストモデル比較）

`is_high` を目的変数とし、温度（連続値）と prompt_type（カテゴリカル）の相対的な説明力をネストモデルの尤度比検定（LRT）で比較した。

**モデル仕様**:
- M_temp: `is_high ~ temp + C(target)`
- M_prompt: `is_high ~ C(prompt_type) + C(target)`
- M_both: `is_high ~ temp + C(prompt_type) + C(target)`

**LRT 結果**（M_both を基準にした追加効果）:

| モデル | prompt_type の追加効果 (M_both vs M_temp) | 温度の追加効果 (M_both vs M_prompt) |
|---|---|---|
| DEVSTRAL | LR = 430.7, p ≈ 0 *** | LR = 0.22, p = 0.64 |
| GEMMA_3N_E4B | LR = 390.1, p ≈ 0 *** | LR = 2.02, p = 0.16 |
| NOVA_2_LITE | LR = 395.3, p ≈ 0 *** | LR = 26.5, p < 0.001 *** |
| NOVA_MICRO | LR = 312.8, p ≈ 0 *** | LR = 1.28, p = 0.26 |

全モデルで **prompt_type が圧倒的に支配的**。温度の追加効果が有意なのは NOVA_2_LITE のみだが、その方向は負（温度上昇で HIGH 率低下）であり、「温度を正しく推定している」とは言えない。

**AIC 比較**（低いほど良い）:

| モデル | M_temp | M_prompt | M_both |
|---|---:|---:|---:|
| DEVSTRAL | 524.5 | **96.0** | 97.8 |
| GEMMA_3N_E4B | 539.5 | **153.4** | 153.4 |
| NOVA_2_LITE | 546.6 | 179.8 | **155.3** |
| NOVA_MICRO | 534.6 | **225.2** | 225.9 |

M_prompt（温度なし・prompt_type あり）が 3/4 モデルで最良。

### 3.4 効果量比較

ロジスティック回帰の予測確率を用いた効果量（確率差）:

- **温度効果**: P(HIGH | temp=0.9) − P(HIGH | temp=0.1)（NORMAL 条件、ベースターゲット固定）
- **プロンプト効果**: P(HIGH | CRAZY) − P(HIGH | FACTUAL)（temp=0.5 固定）

![効果量比較](../output/figures/blog_effect_size.png)

| モデル | 温度効果（確率差） | プロンプト効果（確率差） |
|---|---:|---:|
| DEVSTRAL | 0.003 | 0.987 |
| GEMMA_3N_E4B | 0.043 | 1.000 |
| NOVA_2_LITE | −0.574 | 1.000 |
| NOVA_MICRO | 0.039 | 0.937 |

DEVSTRAL・GEMMA_3N_E4B・NOVA_MICRO ではプロンプト効果が温度効果の **23〜330 倍**に達し、温度の影響は実質的にゼロに近い。一方 NOVA_2_LITE では温度効果が **−0.574**（温度上昇で HIGH 率が大幅に低下）と大きな負の値を示した。これは「温度を正しく推定している」のではなく、NORMAL 条件で温度が上がるほど LOW と判定するという逆方向のバイアスを反映している。

### 3.5 解釈

Study 1 の「温度推定」と呼ばれるタスクは、実質的には **「文体・話題手がかりからの推定」** である。モデルは以下のヒューリスティックに依存している:

- CRAZY 指示 → 奇抜な文 → 「高温に違いない」→ HIGH
- FACTUAL 指示 → 堅実な文 → 「低温に違いない」→ LOW
- NORMAL 指示 → 文の印象次第 → 不安定

温度パラメータそのものへの感度は統計的にほぼ検出されない。

---

## 4. Study 2 の結果: privileged self-access の検証

### 4.1 条件別精度（accuracy）

| モデル | self | within | across | n |
|---|---:|---:|---:|---:|
| NOVA_MICRO | 0.548 | 0.496 | 0.459 | 405 |
| NOVA_2_LITE | 0.464 | 0.521 | 0.531 | 405 |
| GEMMA_3N_E4B | 0.501 | 0.516 | 0.531 | 405 |
| DEVSTRAL | 0.553 | 0.509 | 0.514 | 405 |

※ across 条件は全モデル総当たりではなく、DEVSTRAL↔GEMMA_3N_E4B および NOVA_2_LITE↔NOVA_MICRO の 2 ペアで実施した。各 generator に対して 1 つの predictor が割り当てられている。

### 4.2 Balanced accuracy / macro-F1 + majority baseline

majority baseline = 0.667（LOW が多数派のため、全て LOW と予測すれば 66.7% の accuracy が得られる）。

| モデル | 条件 | accuracy | balanced acc | macro-F1 |
|---|---|---:|---:|---:|
| NOVA_MICRO | self | 0.548 | 0.532 | 0.524 |
| NOVA_MICRO | within | 0.496 | 0.541 | 0.495 |
| NOVA_MICRO | across | 0.459 | 0.509 | 0.459 |
| NOVA_2_LITE | self | 0.464 | 0.461 | 0.450 |
| NOVA_2_LITE | within | 0.521 | 0.520 | 0.506 |
| NOVA_2_LITE | across | 0.531 | 0.552 | 0.524 |
| GEMMA_3N_E4B | self | 0.501 | 0.502 | 0.487 |
| GEMMA_3N_E4B | within | 0.516 | 0.517 | 0.502 |
| GEMMA_3N_E4B | across | 0.531 | 0.507 | 0.502 |
| DEVSTRAL | self | 0.553 | 0.506 | 0.505 |
| DEVSTRAL | within | 0.509 | 0.509 | 0.494 |
| DEVSTRAL | across | 0.514 | 0.513 | 0.499 |

注目すべき点:

- **全条件が majority baseline（0.667）を下回る**: 全モデル・全条件の accuracy が majority baseline を大きく下回っており、「全て LOW」と答えるナイーブ戦略にすら負けている。
- **balanced accuracy はおおむね 0.50 付近**: クラス不均衡を補正すると、実質的にランダム水準。

### 4.3 Δ(self − within) と bootstrap CI

![フォレストプロット](../output/figures/blog_study2_delta.png)

| モデル | Δ(self − within) | 95% CI |
|---|---:|---|
| NOVA_MICRO | +0.052 | [0.000, +0.101] |
| NOVA_2_LITE | −0.057 | [−0.101, −0.012] |
| GEMMA_3N_E4B | −0.015 | [−0.040, +0.010] |
| DEVSTRAL | +0.044 | [+0.007, +0.084] |

- NOVA_MICRO: CI の下限が 0.000 でぎりぎり self 優位だが、実質的に微小差。
- NOVA_2_LITE: **self が有意に劣る**（Δ < 0, CI が 0 を含まない）。
- GEMMA_3N_E4B: CI が 0 を含み、差なし。
- DEVSTRAL: self がやや優位だが、Δ = +0.044 は実用的に微小。

### 4.4 主張: self 優位は一貫しない

4モデル中、self > within は 2 モデル（NOVA_MICRO, DEVSTRAL）で見られるが、self < within も 2 モデル（NOVA_2_LITE, GEMMA_3N_E4B）で見られる。方向すら揃わないため、**モデル横断で privileged self-access の一貫した証拠は得られない**。

これは参照論文の結論（self-reflection は within/across より優位でない）と整合する。

---

## 5. 未知語の影響

「アイレット・ドコドコ・ヤッタゼ・ペンギン」は実在しない造語4連語であり、モデルの知識ベースに存在しない。この条件での挙動は以下の通り。

- **FACTUAL**: 「実在しない」というメタ判断が発動し、簡潔な否定文（例:「アイレット・ドコドコ・ヤッタゼ・ペンギンは実在しません。」）が生成される → LOW に安定（正解しやすい）。
- **NORMAL / CRAZY**: 知識がないため創造的な文が出やすく（例:「空飛ぶカヌーで火星の氷を食べています！」）、温度を HIGH と誤推定しやすい。

Spearman 分析でも、この対象語の CRAZY 条件は DEVSTRAL を除く全モデルで NaN（HIGH 率が定数 = 温度非感度）を示した。DEVSTRAL でも ρ = 0.10（p = 0.77）と非有意であり、実質的に温度非感度と言える。

この結果は、未知語対象が「温度推定性能」ではなく「文体バイアス耐性」を測るストレス条件として機能することを示唆する。今後の実験設計では、主評価（実在語・中立条件）とストレス評価（未知語・CRAZY）を分離して報告すべきである。

---

## 6. エラー分析

代表的な誤判定パターンを以下に示す。

| パターン | モデル | 条件 | 実温度 | 判定 | 生成文（抜粋） | 推定理由（抜粋） |
|---|---|---|---:|---|---|---|
| NORMAL→HIGH | NOVA_2_LITE | ゾウ | 0.0 | HIGH | 「アフリカの草原で、象はその巨大な体と長大な鼻で…」 | 「具体的な場面と詳細な記述…高い温度パラメータの特徴と一致」 |
| NORMAL→HIGH | NOVA_2_LITE | アイレット | 0.0 | HIGH | 「アイレットはドコドコとヤッタゼのペンギンたちと海辺で…」 | 「キャラクター間の友好的な相互作用…創造性と表現の自由が反映」 |
| NORMAL→HIGH | NOVA_MICRO | ゾウ | 0.1 | HIGH | 「ゾウはアフリカの大草原を優雅に歩き回る巨大な動物です。」 | 「具体的で、想像力を刺激する…創造性に富んでいます」 |
| NORMAL→HIGH | NOVA_MICRO | アイレット | 0.0 | HIGH | 「アイレット…は、遠くで見える小さな点のような姿が特徴的な生き物です。」 | 「意味不明な単語…カジュアルで遊び心のあるトーン」 |
| CRAZY→LOW | NOVA_MICRO | ゾウ | 0.6 | LOW | 「ゾウは月夜に踊りながら、宇宙から降ってくるチョコレートを歌って…」 | 「非常に奇抜で、現実離れした内容…しかし根拠がほとんどないため LOW」 |
| CRAZY→LOW | NOVA_MICRO | マーロック | 0.0 | LOW | 「マーロックは巨大な宇宙戦艦の中で、月夜に踊る謎の生物と…」 | 「想像力豊かで奇抜な要素…しかし具体的な文脈やストーリーラインはありません」 |

**抽出されるヒューリスティック**:

1. **「情報量 = 高温」**: 詳細な描写や複数の要素を含む文を「高温で生成された」と判断する傾向。実際には低温でも詳細な事実文は生成される。
2. **「創造性 = 高温」**: 創造的・奇抜な内容を高温の証拠とみなす。CRAZY プロンプトではこれが常に発動するため飽和する。
3. **「事実的 = 低温」**: 事実の羅列を低温の証拠とみなす。FACTUAL プロンプトで安定して LOW になる主因。

**説明と判定の不整合**: CRAZY→LOW の少数例（主に NOVA_MICRO で観察）では、reasoning 本文が「奇抜で想像力豊か」と高温を示唆しつつ、最終判定が LOW になるケースがある。これは判定段での保守的バイアス、または出力整合性の揺らぎを示す。

---

## 7. 制限事項と妥当性への脅威

1. **閾値ラベリングで中間温度を除外**: LOW ≤ 0.5, HIGH ≥ 0.8 により、0.6–0.7 の温度帯を除外している。これは分類問題を「極端な2値分類」に単純化しており、温度の連続的な変化をとらえきれない。
2. **LOW/HIGH 比率の不均衡（6:3 = 2:1）**: majority baseline が 0.667 となるため、accuracy だけでは性能を過大評価しうる。balanced accuracy と macro-F1 で補正して報告した。
3. **Study 2 予測プロンプトが prompt_type / target を提示**: 予測側が文体手がかりを利用しやすくなり、within/across の精度を底上げする方向に働く。self-reflection の相対的優位を検出しにくくなる可能性がある。
4. **小規模モデル4種・3ループ限定**: サンプルサイズが限られており、モデル間差の検出力が低い。大規模モデルでは異なる結果が出る可能性がある。
5. **日本語のみ**: 英語や他言語への一般化は未検証。日本語固有の語彙・表記（漢字/カナ）の影響が結果に含まれている。

---

## 8. まとめと今後の展望

### Q1 への回答: 温度推定は温度そのものを反映しているか？

**No.** ロジスティック回帰の結果、prompt_type が全モデルで圧倒的に支配的であり（LR > 312, p ≈ 0）、温度の追加効果は 3/4 モデルで有意でない。Spearman 相関でも温度との有意な正の単調関係はほぼ見られない。Study 1 の「温度推定」は、実質的に「文体・話題手がかりへの反応」を測定している。

### Q2 への回答: self-reflection は第三者より有利か？

**No.** Δ(self − within) は4モデル中2モデルで正、2モデルで負であり、方向すら一貫しない。Bootstrap 95% CI を見ても、一貫した self 優位の証拠はない。これは参照論文の結論と整合する。

### 今後の展望

- **prompt_type を予測側に渡さない派生実験**: 文体手がかりを遮断した場合に within/across の精度がどの程度低下するかを検証する。
- **温度の連続値回帰**: HIGH/LOW の2値分類ではなく、温度値そのものの回帰推定を試みることで、感度の連続的な評価が可能になる。
- **CRAZY / 未知語のストレス評価分離**: 主評価（NORMAL + 実在語）とストレス評価（CRAZY + 未知語）を明示的に分離し、それぞれの条件でのモデル性能を独立に報告する。
- **大規模モデルとの比較**: 本追試は小規模モデルに限定されており、大規模モデルで privileged self-access が発現するかは別途検証が必要。
- **多言語展開**: 日本語以外の言語で同様の実験を行い、言語依存性を評価する。
